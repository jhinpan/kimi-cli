"""
MetadataStore - JSONL-based sidecar storage for tagging and metadata tracking.

This module provides structured metadata storage alongside the main conversation history,
designed to support KV-cache-native context management in the future.
"""

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Literal

import aiofiles

from kimi_cli.utils.logging import logger


@dataclass
class PinRecord:
    """Represents a pinned context region for retention during compaction."""

    task_id: str
    message_ids: list[str]
    policy: Literal["pin_outcome", "pin_process", "auto"]
    ttl_steps: int
    importance: int
    notes: str | None
    created_at_step: int


@dataclass
class TodoTaskMap:
    """Represents a mapping between a todo and a task."""

    todo_id: str
    task_id: str


class MetadataStore:
    """
    Manages structured metadata storage in a JSONL sidecar file.

    The metadata store keeps track of:
    - Tag records: Associate messages with retention policies
    - Map records: Link todos to tasks
    - Artifact records: Track generated artifacts (future use)

    Format: Each line is a JSON record with a "type" field:
    - {"type": "tag", "task_id": "...", "message_ids": [...], "policy": "...", ...}
    - {"type": "map", "todo_id": "...", "task_id": "..."}
    - {"type": "artifact", "task_id": "...", "kind": "...", ...} (future)
    """

    def __init__(self, path: Path):
        """
        Initialize metadata store.

        Args:
            path: Path to the metadata JSONL file (typically .meta.jsonl)
        """
        self._path = path
        self._current_step = 0

    async def _append_record(self, record: dict) -> None:
        """Append a record to the metadata file."""
        logger.debug("Appending metadata record: {record}", record=record)
        self._path.parent.mkdir(parents=True, exist_ok=True)

        async with aiofiles.open(self._path, "a", encoding="utf-8") as f:
            await f.write(json.dumps(record) + "\n")

    async def tag(
        self,
        *,
        task_id: str,
        message_ids: list[str],
        policy: Literal["pin_outcome", "pin_process", "auto"],
        ttl_steps: int,
        importance: int,
        notes: str | None = None,
    ) -> None:
        """
        Tag messages with a retention policy for future KV-cache compaction.

        Args:
            task_id: The task ID these messages belong to
            message_ids: List of message IDs to tag
            policy: Retention policy ("pin_outcome", "pin_process", "auto")
            ttl_steps: Time-to-live in agent steps
            importance: Priority level (1-5)
            notes: Optional human-readable notes
        """
        record = {
            "type": "tag",
            "task_id": task_id,
            "message_ids": message_ids,
            "policy": policy,
            "ttl_steps": ttl_steps,
            "importance": importance,
            "notes": notes,
            "created_at_step": self._current_step,
        }
        await self._append_record(record)

    async def map_todo_task(self, todo_id: str, task_id: str) -> None:
        """
        Create a mapping between a todo and a task.

        Args:
            todo_id: The todo ID
            task_id: The task ID
        """
        record = {
            "type": "map",
            "todo_id": todo_id,
            "task_id": task_id,
        }
        await self._append_record(record)

    async def record_artifact(
        self, task_id: str, kind: str, path: str | None = None, bytes_size: int | None = None
    ) -> None:
        """
        Record an artifact generated by a task (for future use).

        Args:
            task_id: The task ID that generated this artifact
            kind: Type of artifact (e.g., "diff", "code", "output")
            path: Optional file path
            bytes_size: Optional size in bytes
        """
        record = {
            "type": "artifact",
            "task_id": task_id,
            "kind": kind,
            "path": path,
            "bytes": bytes_size,
        }
        await self._append_record(record)

    async def list_active_pins(self, current_step: int | None = None) -> list[PinRecord]:
        """
        List all active (non-expired) pin records.

        Args:
            current_step: Current agent step number for TTL calculation.
                         If None, uses self._current_step.

        Returns:
            List of PinRecord objects, sorted by importance (highest first)
        """
        if current_step is None:
            current_step = self._current_step

        if not self._path.exists():
            return []

        pins: list[PinRecord] = []

        async with aiofiles.open(self._path, "r", encoding="utf-8") as f:
            async for line in f:
                if not line.strip():
                    continue

                try:
                    record = json.loads(line)
                    if record.get("type") != "tag":
                        continue

                    created_at = record.get("created_at_step", 0)
                    ttl = record.get("ttl_steps", 0)
                    expires_at = created_at + ttl

                    # Check if pin is still active
                    if expires_at > current_step:
                        pin = PinRecord(
                            task_id=record["task_id"],
                            message_ids=record["message_ids"],
                            policy=record["policy"],
                            ttl_steps=record["ttl_steps"],
                            importance=record["importance"],
                            notes=record.get("notes"),
                            created_at_step=created_at,
                        )
                        pins.append(pin)
                except (json.JSONDecodeError, KeyError) as e:
                    logger.warning("Failed to parse metadata record: {error}", error=e)
                    continue

        # Sort by importance (descending)
        pins.sort(key=lambda p: p.importance, reverse=True)
        return pins

    async def list_todo_task_maps(self) -> list[TodoTaskMap]:
        """
        List all todo-task mappings.

        Returns:
            List of TodoTaskMap objects
        """
        if not self._path.exists():
            return []

        maps: list[TodoTaskMap] = []

        async with aiofiles.open(self._path, "r", encoding="utf-8") as f:
            async for line in f:
                if not line.strip():
                    continue

                try:
                    record = json.loads(line)
                    if record.get("type") != "map":
                        continue

                    todo_map = TodoTaskMap(
                        todo_id=record["todo_id"],
                        task_id=record["task_id"],
                    )
                    maps.append(todo_map)
                except (json.JSONDecodeError, KeyError) as e:
                    logger.warning("Failed to parse metadata record: {error}", error=e)
                    continue

        return maps

    def increment_step(self) -> None:
        """Increment the current step counter."""
        self._current_step += 1

    @property
    def current_step(self) -> int:
        """Get the current step number."""
        return self._current_step
